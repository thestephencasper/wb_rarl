TODO
see how to make the adv observe the agent's inner state
see the 'cheating' arg for some help on how to modify the adv's observation space
see what a PPOTFPolicy is
https://github.com/ray-project/ray/blob/master/rllib/agents/ppo/ppo_tf_policy.py


# setup
# install docker
# sudo chmod 666 /var/run/docker.sock
docker build -t wb_rarl:v0 .
# sudo systemctl restart docker  # may be needed if some sort of gpu bug
# docker run -it --rm --name wb_rarl_scasper --gpus all wb_rarl:v0 bash
docker run -it --rm --name wb_rarl_scasper wb_rarl:v0 bash
### PROBLEM ###
# The cuda version on the align machines isn't compatible with tf 1.15.0, so no gpu
# options, run on staori, run on gpu, or figure this out
### PROBLEM ###
git clone https://github.com/thestephencasper/wb_rarl.git
cd
mkdir .mujoco
cd .mujoco
wget https://mujoco.org/download/mujoco210-linux-x86_64.tar.gz
tar -xvf mujoco210-linux-x86_64.tar.gz
cd /wb_rarl/wb_rarl
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/root/.mujoco/mujoco210/bin
ln -s /usr/lib/x86_64-linux-gnu/libGL.so.1 /usr/lib/x86_64-linux-gnu/libGL.so
mkdir results

# 1 adv run
python run_adv.py --env_name hopper --train_batch_size 100000 --num_iters 700 --checkpoint_freq 2 \
--num_concat_states 1 --num_adv_strengths 1 --advs_per_strength 1 --advs_per_rew 1 --num_adv_rews 1 --adv_strength 0.25 \
--exp_title rarl_1_adv --num_cpus 10 --adv_all_actions --concat_actions --lambda_val 1.0 --lr 0.0005 # --run_transfer_tests

# 5 adv run
python run_adv.py --env_name hopper --train_batch_size 100000 --num_iters 4 --checkpoint_freq 1 \
--num_concat_states 1 --num_adv_strengths 1 --advs_per_strength 5 --advs_per_rew 1 --num_adv_rews 5 --adv_strength 0.25 \
--exp_title rarl_5_adv --num_cpus 10 --adv_all_actions --concat_actions --lambda_val 1.0 --lr 0.0005 # --run_transfer_tests

https://github.com/ray-project/ray/issues/7983
$ ls ~/ray_results/rarl_5_adv
PPO_0_2022-05-27_03-22-52bv1szbcm  experiment_state-2022-05-27_03-22-52.json

# get results from run
~/ray_results/rarl_control/experiment_state/* ['checkpoints'][0]['last_result'] keys 'policy_reward_min', 'policy_reward_mean', 'policy_reward_max'
# get transfer results
~/transfer_results/adv_robust/*/rarl_control/*






# OLD

# sudo apt-get install python3.6
# sudo apt-get install python3.6-dev
python3.6 -m venv ~/rarl_env
source ~/rarl_env/bin/activate
# sudo apt install libosmesa6-dev libgl1-mesa-glx libglfw3
# download mujoco210 into /root/.mujoco
# export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/root/.mujoco/mujoco210/bin
# ln -s /usr/lib/x86_64-linux-gnu/libGL.so.1 /usr/lib/x86_64-linux-gnu/libGL.so
pip install --upgrade pip
pip install tensorflow-gpu==1.15.0
pip install numpy==1.17.1 gym==0.14.0 lz4==2.2.1 requests==2.22.0 \
matplotlib opencv-python==4.1.0.25 gym==0.14.0 awscli==1.16.259 pytest==5.2.1 \
ray[tune] ray[rllib] ray==0.8.0 mujoco-py patchelf scipy psutil
pip install --pre pytz
pip install --upgrade Pillow
# edit run_scripts/mujoco/run_adv_mujoco.py to have sys.path.append('/project/robust_RL_multi_adversary/')

